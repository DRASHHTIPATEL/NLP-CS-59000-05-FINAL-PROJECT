{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7tR5D4VdUI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9ed878-bd30-48e3-85e7-d1afe597ae4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B2B83i8hZIr",
        "outputId": "cd07222a-c179-437b-9088-f8a244f4aa59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "squrlig-s4Ze",
        "outputId": "f518504b-c249-4280-fae5-ef73ea3cba4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE0eeoZPikit",
        "outputId": "638a5ef2-1408-451b-a8fa-7cae06f4172d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feKUpKaghIEb",
        "outputId": "0d04fdf5-deb7-45a1-dbf0-c58c663eab86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrcA2xM642Nw",
        "outputId": "ccf20dfe-afd1-40dc-9a02-d244eef21248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.8 (from langchain_community)\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.9-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-core-0.3.21 langchain_community-0.3.9 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEQHObeXFL0d"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "import base64\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain.prompts import PromptTemplate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9mW_rnKhADp"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import QAGenerationChain\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "import json\n",
        "import time\n",
        "from PyPDF2 import PdfReader\n",
        "import csv\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_rbU0X-hSPs"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACEHUB_API_TOKEN = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Document & TextProcessing**"
      ],
      "metadata": {
        "id": "mb6h45nKn8oI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovqMQJAxW1Ce"
      },
      "outputs": [],
      "source": [
        "def pdf_directory_loader(pdf_directory_path):\n",
        "  loader = PyPDFDirectoryLoader(pdf_directory_path)\n",
        "  docs = loader.load_and_split()\n",
        "  return docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r50bfhjOXgxm"
      },
      "outputs": [],
      "source": [
        "def text_split(extracted_data):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
        "    text_chunks = text_splitter.split_documents(extracted_data)\n",
        "\n",
        "    return text_chunks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVLDL9lSZbsm",
        "outputId": "96a9a178-82d7-4e89-fcba-0a15c750f263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSibgDPA3O5C"
      },
      "outputs": [],
      "source": [
        "text = pdf_directory_loader(\"/content/drive/MyDrive/NLP_PROJECT\")\n",
        "text_chunks = text_split(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul0FglHaYqmp",
        "outputId": "f086d859-33c1-4339-d801-5f1c0ed56ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='Chapter on Machine Learning\\nBy Jeﬀ Edmonds\\nComputers can now drive cars and ﬁnd cancer in x-rays. For bet ter or worse, this will change the world (and\\nthe job market). Strangely designing these algorithms is no t done by telling the computer what to do or\\neven by understanding what the computer does. The computers learn themselves from lots and lots of data\\nand lots of trial and error. This learning process is more ana logous to how brains evolved over billions of'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='years of learning. The machine itself is a neural network whi ch models both the brain and silicon and-or-not\\ncircuits, both of which are great for computing. The only diﬀ erence with neural networks is that what they\\ncompute is determined by weights and small changes in these w eights give you small changes in the result\\nof the computation. The process for ﬁnding an optimal settin g of these weights is analogous to ﬁnding the'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='bottom of a valley. “Gradient Decent” achieves this by using the local slope of the hill (derivatives) to direct\\nthe travel down the hill, i.e. small changes to the weights. T here is some theory. If a machine is found that\\ngives the correct answers on the randomly chosen training da ta without simply memorizing, then we can\\nprove that with high probability this same machine will also work well on never seen before instances.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='Coding: When writing computer code, the instructions are painstaki ngly written by humans. This works\\ngreat for simple repetitive tasks. Expert systems of the 80’ s however failed. Though we are able to\\nwalk, it is hard to explaining how to do it!!!\\nMachine Learning: When designing neural networks, the instructions are 100% d ictated by weights\\n⟨w1, . . . , w m⟩. Like the brain, these are way too hard to understand. They ar e learned using a simple'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='algorithm, ﬁnding patterns in lots of data. Walking, for exa mple, has enough of a pattern that machine\\nlearning can copy it.\\nEvolution: Add just a little random change that is encouraged by some fee d back to go in the right direction\\nand the Emergent Complexity that arises is awe inspiring. I ﬁnd the parallels between evo lution and\\nmachine learning oddly spiritual.\\nHopeful Applications: Self diving cars, image processing, speech processing, rob ots, art, medical, ﬁnan-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='cial, and legal experts. Hopefully these will make the world a better place.\\nScary Applications: People losing their jobs, the system watching you, ads custo mized to you, cyberse-\\ncurity picking out “criminals” in a crowd, killing machines , machines deciding your fate. These might\\nmake the world a worse place.\\nAbstract Thinking: We can talk about many aspects of machine learning without ne eding to know the'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}, page_content='nature of the machine or the nature of the data. We talk of know ing if image is a face without\\nmentioning noses. This simplicity let’s us focus on what is i mportant and ensures that what we say\\nworks for any model of machine and for any computational prob lem.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='Supervised Training Data: The input that we receive is a set of input/output pairs\\n{⟨⃗ x1, y1⟩, ⟨⃗ x2, y2⟩, . . . , ⟨⃗ xD, yD⟩}. In order to be able to draw a simple graph for intuitive pur-\\nposes, we pretend each input ⃗ xd is a real numbers. But more likely it is something complex lik e\\nan image. For each such input, yd is the answer provided by a Supervisor. When yd is a single\\nreal number, we call the process regression. When yd is a label like cat or dog, we call the process'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='categorizing. Another way of visualizing the data is to assume that each in put ⃗ xd is some point in\\nsome height dimensional space and the supervisor’s answer ys is indicated by the colour of the point.\\nCat: If the input ⃗ xd is an image of a cat, then the computer just sees a big matrix of numbers. From this,\\nmeaning must be extracted. This seems to me to be magic. On the other hand, the brain manages to\\ndo it.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='do it.\\nMachine: Our goal is to build a machine M⃗ w(⃗ x) that takes an input ⃗ xand returns an answer y. It is\\nparametrized by a vector of m real valued weights ⃗ w= ⟨w1, . . . , w m⟩. This includes anything that the\\nlearning process learns and remembers about the data and use s later to make predictions.\\nLinear and Non-Linear Regression: For example, yd might be the likelihood of rain on day d, x⟨d,1⟩'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='whether there are clouds, x⟨d,2⟩ which the colour of coat the man is wearing, and ⟨w1, w2⟩ their level of\\neﬀect on rain. Our machine might might then approximate yd with M⃗ w(⃗ xd) = w0 +w1x⟨d,1⟩ +w2x⟨d,2⟩.\\nWho knows, maybe if people are wearing yellow coats, then the se might be rain coats and hence it is\\nmore likely to rain. The model designer could make the types o f machines learned more powerful by'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='adding additional terms like + w3 x⟨d,2⟩2. Here x⟨d,2⟩2 is a hand picked precomputed features of the\\ninput ⃗ xd and w3 is its weight that is learned during the learning process. Th ough this machine is now\\nnon-linear in the input ⃗ xd, we still call this linear regression, because the answer is linear in the learned\\nweights w3. In contrast, learning M⃗ w(⃗ xd) = x⟨d,1⟩w1 + x⟨d,2⟩w2 , being non-linear in the weights, would\\nbe much harder.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='be much harder.\\nNeural Networks: Our machine might also be something much more complex like a neural network . All\\nyou need to know now about it now is that how it computes y = M⃗ w(⃗ x) is dictated by its weights\\n⃗ w= ⟨w1, . . . , w m⟩.\\nError: Given some setting ⃗ w= ⟨w1, . . . , w m⟩ of the weights, we want to measure how well the machine\\nM⃗ w(⃗ x) does at getting the correct answers y on the training data {⟨⃗ x1, y1⟩, ⟨⃗ x2, y2⟩, . . . , ⟨⃗ xD, yD⟩}.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='The easiest thing to do would be to count the fraction of the da ta set for which the machine gets\\nthe correct answer, namely yd = M⃗ w(⃗ xd). However, this gives little feedback on how to improve the\\nmachine. If answer y is a real number, the diﬀerence yd − M⃗ w(⃗ xd) gives us a measure of how close\\nour machine is to the correct answer. We could take the absolu te value of this |yd − M⃗ w(⃗ xd)| because'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='we do not care which direction the error is in, but |z| is too pointy at z = 0 making the math near\\nimpossible. Instead, we square it and sum over all data items , namely E( ⃗ w) = ∑\\nd(yd − M⃗ w(⃗ xd))2.\\nWhen the answer y is a category like “cat”, we can have the machine instead prod uce a real number\\ntelling us the “probability” that it thinks it is a “cat”. The error would then be based on how close\\nthe probability of the correct answer is to one.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}, page_content='Machine Learning: Given the training data, our goal is to ﬁnd the weights ⃗ wopt that minimizes the error\\nE( ⃗ w). This is all that machine learning is.\\n2'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='Error Surface: We think of the error as a function of the weights ⃗ wbecause they are the parameters that\\nwe are able to tweak. If we pretend that the weights consist of one real number ⃗ w= ⟨w1⟩, then we\\ncan graph the error function on paper with w1 being the x-axis and the error E( ⃗ w) being the y-axis.\\nWe are looking for a minimum. With two real numbers ⃗ w= ⟨w1, w2⟩, we get an error surface. The'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='ﬁrst weight w1 can tell you your East-West location, the second w2 your North-South location, and\\nthe error E( ⃗ w) your altitude. This gives you a topological map of your erro r surface. We are looking\\nfor a location ⃗ win a valley.\\nBlind: In practice the weights ⃗ w= ⟨w1, . . . , w m⟩ consist of tens or hundreds of thousands of real numbers\\nmaking for a very high dimensional space to search. With 10,0 00 weights with 0 to 9 integer values,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='there are 10 10,000 settings of the weights. A super computer on each atom of the u niverse working for\\nthe age of the universe couldn’t dent this list!\\nLinear Regression: If the machines are linear in the weights as in M⃗ w(⃗ xd) = w0 + w1x⟨d,1⟩ + w2x⟨d,2⟩ +\\nw3 x⟨d,2⟩2, then there are formulas that will give you the weights ⃗ wopt that minimizes the error E( ⃗ w).\\nNot so for complicated machines.\\nGradient Decent: When I asked my young son how to ﬁnd the top of the hill, he answe red “Just keep'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='going up.” When ask which direction to head, he answered “in t he direction that is steepest.” When\\nask how do you know when you are at the top, he answered “When yo u can’t go up anymore.” This\\nis how we will ﬁnd the bottom of a valley. It might not ﬁnd the global minimum, but we hope that it\\nﬁnds a machine that is good enough for our purposes. From this we get self driving cars!\\nSmooth/Diﬀerentiable: This error surface is such that an inﬁnitesimally small chan ge in any one of the'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='weights wk causes an inﬁnitesimally small change in the output of the co rresponding neuron of the\\nneural net, in the output M⃗ w(⃗ xd) of the machine, and in the error E( ⃗ w) = ∑\\nd(yd −M⃗ w(⃗ xd)2. Dividing\\nthe change in E( ⃗ w) by the change in wk gives the derivative δE\\nδwk\\n. The vector of these derivatives\\n∆( ⃗ w) =\\n⣨\\nδE\\nδw1\\n, δE\\nδw2\\n, . . . , δE\\nδwm\\n⟩\\nis called the gradient. This is computed eﬃciently by a process called'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='back-propagation using the calculus learned in high school. The ﬁgure below pr ovides a little of the\\nmath as to why this vector gives the direction of steepest dec ent. Intuitively, the weights wk that\\ninﬂuence correct answers are increased and those that inﬂue nce wrong answers are decreased.\\nAlgorithm: Method for ﬁnding weights ⃗ wopt that minimizes the error E( ⃗ w) is as follows:\\nStart with random ⃗ w= ⟨w1, . . . , w m⟩\\nRepeat:\\n⟨loop−invariant⟩: We know where we are ⃗ w= ⟨w1, . . . , w m⟩.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}, page_content='Calculate our height E( ⃗ w).\\n3'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='Calculate the direction and slope of steepest descent.\\nChange⃗ wby a small step in this direction and distance proportional t o the slope.\\nStop when every direction is up.\\nGeneralizing: This machine is optimized to do well on the training data. But how well does it generalize\\nto other inputs that it has never seen before? There is a “no fr ee lunch” theorem that says that no\\none method works in all cases. But there are a few principles. Consider the following three examples,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='A, B, & C. Each dot give the ⟨xd, yd⟩ of one training data item. The curve gives the answer that the\\nmachine gives for each input x. Ask yourself which of these three gives the best answers for values of\\nx that it has never seen before?\\nUnderﬁtting: A is an example of Underﬁtting in which the class of machines just doesn’t have the\\ncapacity to learn the material.\\nOverﬁtting: C is an example of Overﬁtting in which the class of machines is so powerful that is can'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='memorize the answers for just about any function. The proble m is that if you cheat on the exam\\nby making a table of all the answers you were taught, then you l earn nothing and are stuck when\\na new question comes.\\nCompression: B seems like a good balance of under and over ﬁtting. On a test, if you summarize the\\nlearned material, compressing it to all ﬁt on one “cheat shee t”, then hopefully you understand it'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='and do well when a new question comes. Compression occurs whe n the weights ⃗ w= ⟨w1, . . . , w m⟩\\nwith which the machine learns, does not contain enough bits o f information to store the training\\ndata answers ⟨y1, . . . , y D⟩.\\nRegularization: A common way to ﬁnd this balance is to minimize not just the err or but a sum of\\nthe error and of some measure of how complex your machine is. W illiam of Ockham says “All\\nthings being equal, the simplest solution tends to be the bes t one.”'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='Theory: Learnable Probably Approximately Correct (PAC): If on the randomly chosen\\ntraining data, a machine is found that gives good answers, ev en though compression is required,\\nthen we can prove that with high probability this same machin e will also work well on never seen\\nbefore instances. The proof does not measure the quality of t he machine but of the training data.\\nIf the data is chosen randomly then with high probability it i s representative of the entire universe\\nof possible data.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='of possible data.\\nNeural Networks: Let’s now understand neural networks in more detail. It is ma de of layers of artiﬁcial\\nneurons. The input layer has an input wire for each pixel of th e input image receiving a value between\\n0-1 indicating the pixel’s brightness. The output layer has a wire for each category indicating the\\n“probability” that the input image is in fact a cat or dog. In b etween, the layers are said to be'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}, page_content='hidden. These have no human designated meaning. Meaning is “learne d” by choosing weights ⃗ w=\\n⟨w1, . . . , w m⟩.\\n4'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}, page_content='When a neuron in the brain ﬁres, it sends a signal to its neighbors across it s synapses. These synapses\\nhave diﬀerent weights in their inﬂuence. When a neuron’s inc oming signal reaches a threshold it ﬁres.\\nSimilarly, an artiﬁcial neuron takes a real valued signal xi along each of its incoming edges, multiplies\\nthis by the edge’s weight wi, and ﬁres if the weighted sum z = ∑\\ni=0..n xiwi reaches its threshold. In'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}, page_content='this way, a neuron is able to compute a And, Or, or Not gate and hence is powerful enough to be able\\nto compute anything a digital computer can compute. So we can later do gradient decent, we change\\nthe threshold activation y = σ(z) so that it transitions gracefully. Instead of YES/NO we all ow maybe\\nso, i.e. if the weighted sum is close to its threshold, then it outputs a half instead of 0-1.\\nVectors: Let’s try to understand how to best think about all of these nu mbers. A data input ⃗ x='),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}, page_content='⟨x1, . . . , x m⟩, eg a image of a cat, is just a large tuple of real values. As suc h it can be thought as\\na point in some high dimensional vector space. Whether the im age is of a cat or a dog partitions\\nthis vector space into regions. Classifying your image amou nts to knowing which region the\\ncorresponding point is in. A linear separator separates two regions with a plane. It is unlikely\\nthat this will work to separate cats from dogs. Instead, each layer of the neural network transforms'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}, page_content='the input ⃗ xuntil it can categorize it.\\nCorrelation of Vectors: Machine Learning is all about ﬁnding complex correlations. Suppose I am\\nstarting a dating service. For each client I will collect pro perties. For each pair of clients, we\\nmeasure how compatible they are. The ﬁrst two clients in the ﬁ gure below each like movies a\\nlot. This adds 15 × 20 = 300 to their compatibility. They are both neutral on natu re, adding'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}, page_content='only 3 × 2 = 6. They diﬀer on being extroverted making them ( −20) × 30 = −600 incompatible.\\nSumming over all properties gives a total compatibility of - 874, i.e. incompatible. The ﬁrst and\\nthird client with 910 are much more compatible.\\n5'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}, page_content='Denote the vector/tuple of values for the ﬁrst client with ⃗ w= ⟨w1, . . . , w m⟩ and with the second\\nwith ⃗ x= ⟨x1, . . . , x m⟩, their compatibility( ⃗ w, ⃗ x) is computed as ∑\\ni wixi. This is called the dot\\nproduct ⃗ w· ⃗ xbetween these vectors. If these vectors are thought of arrow s in high dimensional\\nspace then the angle between them is given by cos(Θ) = ⃗ w·⃗ x\\n| ⃗ w|·|⃗ x| . If ⃗ w· ⃗ xis positive, the angle Θ'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}, page_content='is less than ninety degrees and if it is negative, then it is mo re. If you shine a light perpendicular\\ndown onto ⃗ w, the length of ⃗ x’s projection will be |⃗ x| · cos(Θ) = ⃗ w·⃗ x\\n| ⃗ w| . For some given distance d,\\nthe set of all vectors ⃗ xwith this projection length equaling d are those within the hyper-plane\\nperpendicular to ⃗ wa distance d from the origin. When ⃗ w·⃗ x\\n| ⃗ w| is less than this d, then ⃗ xis on the\\nnear side of this plane and when more than it is on the far side.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}, page_content='Linear Layer = Matrix Multiplication: The simplest layer of a neural network is linear. A novice\\nreading a machine learning paper might not get that many of th e symbols are not real numbers\\nbut are matrices. Hence the product of two such symbols is mat rix multiplication.\\nConsider feeding the dth training data input ⃗ xd =\\n⟨\\nx⟨d,1⟩, . . . , x ⟨d,m⟩\\n⟩\\ninto the neural network. Its\\nith value x⟨d,i⟩ is fed into the network’s ith input wire. The set of all of these values x⟨d,i⟩ can be'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}, page_content='organized into a matrix X =\\n[\\nx⟨d,i⟩\\n]\\n⟨d,i⟩ whose dth row corresponds this dth training data input\\n⃗ xd.\\nLet w⟨i,j⟩ denote the weight of the edge from the ith input wire to the jth artiﬁcial neuron in the\\nﬁrst layer of the network. These values can be also be organiz ed into a matrix W =\\n[\\nw⟨i,j⟩\\n]\\n⟨i,j⟩.\\nThe total incoming signal into the jth hidden neuron on the dth input ⃗ xd is denoted z⟨d,j⟩. Again\\nthese values form a matrix Z =\\n[\\nz⟨d,j⟩\\n]\\n⟨d,j⟩.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}, page_content='[\\nz⟨d,j⟩\\n]\\n⟨d,j⟩.\\nThis jth hidden neuron has many incoming edges, the ith of which is labeled with weight w⟨i,j⟩ and\\nreceives the input value x⟨d,i⟩. These are multiplied and these products for the diﬀerent in coming\\nedges are added together, i.e. z⟨d,j⟩ = x⟨d,1⟩ ×w⟨1,j⟩ +. . . +x⟨d,I⟩ ×w⟨I,j ⟩ = ∑\\ni x⟨d,i⟩ ×w⟨i,j⟩. Note\\nthat this is the exact calculation computed in the matrix mul tiplication Z = X × W as the ⟨d, j⟩'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}, page_content='entry of matrix Z is given by the dot product of the dth row of matrix X and the jth column of\\nmatrix W , summing over index i.\\nNon-Linear Layer: Given signal z⟨d,j⟩, the jth hidden neuron ideally either ﬁres or it doesn’t. The\\npicture is either a cat or not. One might model this by having t he hidden neuron ﬁre if this\\n6'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}, page_content='signal z⟨d,j⟩ passes a threshold. Typically, a constant w⟨0,j⟩ is added into the sum so that the\\nthreshold is shifted to zero. To be more graceful, a typical a ctivation function used is the sigmoid\\nfunction y⟨d,j⟩ = σ(z⟨d,j⟩) that has the hidden neuron output close to one when input sum z⟨d,j⟩ is\\nvery positive, output close to zero when it is very negative, and in between it changes gracefully.\\nThe problem with the sigmoid activation function is that its derivative and hence the gradient'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}, page_content='of steepest decent is close zero for large activation values z making learning slow. To solve this\\nproblem, the rectilinear activation function does not chan ge the signal, i.e. y = z when it is\\npositive and zeros it, i.e. y = 0, when negative. Note for positive z, the slope here is always one\\nmaking learning faster. Recent work has shown that this acti vation function works surprisingly\\nwell for many applications.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}, page_content='Convolution and Recurrent Layer: Suppose the input is an image and the neural network is\\ntrained to ﬁnd a cat. This problem is invariant over the locat ion of the cat, namely the net-\\nwork should answer yes no matter where in the image the cat is l ocated. This invariant can be\\nbuilt into the design of the neural network by having a set of w eights be learned to ﬁnd a feature\\nin some small part of the image and to use those same weights tr anslated all over the image.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}, page_content='Similarly, if the input in a stream of speech, then the same se t of weights can detect the word cat\\nat the beginning and at the end of the stream. These changes de crease the number of weights\\nthat the neural network has, making learning easier, decrea sing computation time, and decreasing\\noverﬁtting.\\nThe Singularity: If technology grows just slightly faster than exponentiall y, then at some point in time,\\nthe expected about of technology will be inﬁnite. What will l ife look like after that?'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}, page_content='7')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "xOpEHu46pom9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS0nUQC8n6Ex"
      },
      "outputs": [],
      "source": [
        "prompt_template=\"\"\"\n",
        "You are an expert at creating questions based on study materials and documentation.\n",
        "Your goal is to prepare a student for their exam.\n",
        "You do this by  asking questions about the text below:\n",
        "\n",
        "{context}\n",
        "\n",
        "Create 10 questions that will prepare students for their exam\n",
        "and make sure you dont generate similar questions\n",
        "and take only scientific important information.\n",
        "\n",
        "Questions:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ov_GQVe-M6A"
      },
      "outputs": [],
      "source": [
        "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\"])\n",
        "chain_type_kwargs={\"prompt\": PROMPT}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Llama-3.2-1B-Instruct\n",
        "    \",\n",
        "    task=\"text2text-generation\",  # Force task type\n",
        "    model_kwargs=dict(temperature=0.1),\n",
        ")\n"
      ],
      "metadata": {
        "id": "rdF12RlVT4V4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd683bad-6b36-4cd5-b351-d83a0f838979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-ab1fa23ff756>:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Wdf74_Fdu4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJj_EQkZXbFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GB-D_0GOeSaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "for chunk in text_chunks:\n",
        "    # Generate questions\n",
        "    question = llm(PROMPT.format(context=chunk))\n",
        "    questions.append(question)"
      ],
      "metadata": {
        "id": "X6kt955VBiLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f150229-644b-4413-cbeb-567ecd7e38a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-ca3097d8c4ad>:4: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  question = llm(PROMPT.format(context=chunk))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHgzZNeKaTwZ",
        "outputId": "8ae98668-48bc-40b9-83aa-0b3612b348e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `lang_token` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `lang_token`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuJukLGPANZU",
        "outputId": "0109f8bf-e31f-4dd6-8f6d-c05c43db76d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Chapter on Machine Learning\\nBy Jeﬀ Edmonds\\nComputers can now drive cars and ﬁnd cancer in x-rays. For bet ter or worse, this will change the world (and\\nthe job market). Strangely designing these algorithms is no t done by telling the computer what to do or\\neven by understanding what the computer does. The computers learn themselves from lots and lots of data\\nand lots of trial and error. This learning process is more ana logous to how brains evolved over billions of' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the chapter on Machine Learning by Jeﬀ Edmonds?\\n2. What is the process of designing algorithms in the context of Machine Learning?\\n3. What is the role of trial and error in the learning process of computers?\\n4. What is the difference between the learning process of computers and the evolution of the brain?\\n5. What is the term for the process of designing algorithms in the context of Machine Learning?\\n6. What is the purpose of the\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='years of learning. The machine itself is a neural network whi ch models both the brain and silicon and-or-not\\ncircuits, both of which are great for computing. The only diﬀ erence with neural networks is that what they\\ncompute is determined by weights and small changes in these w eights give you small changes in the result\\nof the computation. The process for ﬁnding an optimal settin g of these weights is analogous to ﬁnding the' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of a neural network in computing?\\n2. What is the difference between a neural network and a traditional computer?\\n3. What is the process of finding an optimal setting of weights in a neural network?\\n4. What is the purpose of the weights in a neural network?\\n5. What is the difference between a neural network and a traditional computer?\\n6. What is the primary function of a neural network in computing?\\n7. What is the difference between a neural network\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='bottom of a valley. “Gradient Decent” achieves this by using the local slope of the hill (derivatives) to direct\\nthe travel down the hill, i.e. small changes to the weights. T here is some theory. If a machine is found that\\ngives the correct answers on the randomly chosen training da ta without simply memorizing, then we can\\nprove that with high probability this same machine will also work well on never seen before instances.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text?\\n2. What is the purpose of the Gradient Decent algorithm?\\n3. What is the local slope of the hill in the context of Gradient Decent?\\n4. What is the theory behind Gradient Decent?\\n5. What is the significance of the Gradient Decent algorithm in machine learning?\\n6. What is the relationship between Gradient Decent and the concept of memorization?\\n7. What is the key difference between Gradient Decent and other machine\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Coding: When writing computer code, the instructions are painstaki ngly written by humans. This works\\ngreat for simple repetitive tasks. Expert systems of the 80’ s however failed. Though we are able to\\nwalk, it is hard to explaining how to do it!!!\\nMachine Learning: When designing neural networks, the instructions are 100% d ictated by weights\\n⟨w1, . . . , w m⟩. Like the brain, these are way too hard to understand. They ar e learned using a simple' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary purpose of machine learning in the context of neural networks?\\n2. What is the difference between a simple repetitive task and an expert system?\\n3. What is the primary purpose of the instructions in machine learning?\\n4. What is the difference between a neural network and a simple neural network?\\n5. What is the primary purpose of the instructions in neural networks?\\n6. What is the difference between a simple neural network and an expert system?\\n7. What is the primary purpose\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='algorithm, ﬁnding patterns in lots of data. Walking, for exa mple, has enough of a pattern that machine\\nlearning can copy it.\\nEvolution: Add just a little random change that is encouraged by some fee d back to go in the right direction\\nand the Emergent Complexity that arises is awe inspiring. I ﬁnd the parallels between evo lution and\\nmachine learning oddly spiritual.\\nHopeful Applications: Self diving cars, image processing, speech processing, rob ots, art, medical, ﬁnan-' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary goal of machine learning in the context of finding patterns in data?\\n2. What is the term for the process of adding a little random change to a system to encourage it to evolve in the right direction?\\n3. What is the term for the emergence of complex patterns in a system due to the interactions of its components?\\n4. What is the term for the process of using machine learning to analyze and understand the metadata of a dataset?\\n5. What is the term for\",\n",
              " '\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content=\\'cial, and legal experts. Hopefully these will make the world a better place.\\nScary Applications: People losing their jobs, the system watching you, ads custo mized to you, cyberse-\\ncurity picking out “criminals” in a crowd, killing machines , machines deciding your fate. These might\\nmake the world a worse place.\\nAbstract Thinking: We can talk about many aspects of machine learning without ne eding to know the\\' metadata={\\'source\\': \\'/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf\\', \\'page\\': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of machine learning in the context of natural language processing?\\n2. What is the main difference between supervised and unsupervised learning in machine learning?\\n3. What is the role of metadata in machine learning?\\n4. What is the purpose of the \"scary applications\" section in the provided text?\\n5. What is the main concept of abstract thinking in machine learning?\\n6. What is the difference between feature engineering and feature extraction in machine learning?\\n7. What',\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='nature of the machine or the nature of the data. We talk of know ing if image is a face without\\nmentioning noses. This simplicity let’s us focus on what is i mportant and ensures that what we say\\nworks for any model of machine and for any computational prob lem.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 0}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text?\\n2. What is the significance of the term 'image' in the context of machine learning?\\n3. What is the purpose of the term 'noses' in the text?\\n4. What is the relationship between the term 'image' and 'data' in the context of machine learning?\\n5. What is the significance of the term 'face' in the context of machine learning?\\n6. What is the purpose of the term 'n\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Supervised Training Data: The input that we receive is a set of input/output pairs\\n{⟨⃗ x1, y1⟩, ⟨⃗ x2, y2⟩, . . . , ⟨⃗ xD, yD⟩}. In order to be able to draw a simple graph for intuitive pur-\\nposes, we pretend each input ⃗ xd is a real numbers. But more likely it is something complex lik e\\nan image. For each such input, yd is the answer provided by a Supervisor. When yd is a single\\nreal number, we call the process regression. When yd is a label like cat or dog, we call the process' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary purpose of the supervised training data in the given text?\\n2. What is the difference between regression and classification in machine learning?\\n3. What is the role of the Supervisor in the process of supervised training data?\\n4. What is the purpose of pretending each input ⃗ xd is a real numbers in the given text?\\n5. What is the difference between a single real number and a label like cat or dog?\\n6. What is the primary purpose of the metadata\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='categorizing. Another way of visualizing the data is to assume that each in put ⃗ xd is some point in\\nsome height dimensional space and the supervisor’s answer ys is indicated by the colour of the point.\\nCat: If the input ⃗ xd is an image of a cat, then the computer just sees a big matrix of numbers. From this,\\nmeaning must be extracted. This seems to me to be magic. On the other hand, the brain manages to\\ndo it.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text?\\n2. What is the purpose of the supervisor’s answer ys in the context of the data?\\n3. What is the difference between the input ⃗ xd and the supervisor’s answer ys?\\n4. What is the relationship between the input ⃗ xd and the supervisor’s answer ys?\\n5. What is the purpose of the computer’s interpretation of the input ⃗ xd?\\n6. What is the role of the brain in visual\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='do it.\\nMachine: Our goal is to build a machine M⃗ w(⃗ x) that takes an input ⃗ xand returns an answer y. It is\\nparametrized by a vector of m real valued weights ⃗ w= ⟨w1, . . . , w m⟩. This includes anything that the\\nlearning process learns and remembers about the data and use s later to make predictions.\\nLinear and Non-Linear Regression: For example, yd might be the likelihood of rain on day d, x⟨d,1⟩' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary goal of the machine learning model in this text?\\n2. What is the purpose of the vector of weights w in the machine learning model?\\n3. What is the likelihood of rain on day d, represented by yd in the text?\\n4. What is the purpose of the vector of weights w in the machine learning model?\\n5. What is the primary goal of the machine learning model in this text?\\n6. What is the purpose of the vector of weights w\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='whether there are clouds, x⟨d,2⟩ which the colour of coat the man is wearing, and ⟨w1, w2⟩ their level of\\neﬀect on rain. Our machine might might then approximate yd with M⃗ w(⃗ xd) = w0 +w1x⟨d,1⟩ +w2x⟨d,2⟩.\\nWho knows, maybe if people are wearing yellow coats, then the se might be rain coats and hence it is\\nmore likely to rain. The model designer could make the types o f machines learned more powerful by' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main purpose of the machine learning model in this study?\\n2. What is the name of the type of machine that is being learned in this study?\\n3. What is the name of the type of machine that is being used to approximate the value of y in the model?\\n4. What is the name of the type of machine that is being used to approximate the value of y in the model?\\n5. What is the name of the type of machine that is being used\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='adding additional terms like + w3 x⟨d,2⟩2. Here x⟨d,2⟩2 is a hand picked precomputed features of the\\ninput ⃗ xd and w3 is its weight that is learned during the learning process. Th ough this machine is now\\nnon-linear in the input ⃗ xd, we still call this linear regression, because the answer is linear in the learned\\nweights w3. In contrast, learning M⃗ w(⃗ xd) = x⟨d,1⟩w1 + x⟨d,2⟩w2 , being non-linear in the weights, would\\nbe much harder.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='be much harder.\\nNeural Networks: Our machine might also be something much more complex like a neural network . All\\nyou need to know now about it now is that how it computes y = M⃗ w(⃗ x) is dictated by its weights\\n⃗ w= ⟨w1, . . . , w m⟩.\\nError: Given some setting ⃗ w= ⟨w1, . . . , w m⟩ of the weights, we want to measure how well the machine\\nM⃗ w(⃗ x) does at getting the correct answers y on the training data {⟨⃗ x1, y1⟩, ⟨⃗ x2, y2⟩, . . . , ⟨⃗ xD, yD⟩}.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of the weights in a neural network?\\n2. What is the purpose of the activation function in a neural network?\\n3. What is the difference between a supervised and unsupervised learning algorithm?\\n4. What is the role of the error function in neural networks?\\n5. What is the purpose of the bias term in a neural network?\\n6. What is the difference between a feedforward network and a recurrent neural network?\\n7. What is the purpose of the\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='The easiest thing to do would be to count the fraction of the da ta set for which the machine gets\\nthe correct answer, namely yd = M⃗ w(⃗ xd). However, this gives little feedback on how to improve the\\nmachine. If answer y is a real number, the diﬀerence yd − M⃗ w(⃗ xd) gives us a measure of how close\\nour machine is to the correct answer. We could take the absolu te value of this |yd − M⃗ w(⃗ xd)| because' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the machine learning model in the given text?\\n2. What is the formula for calculating the difference between the correct answer and the machine's answer?\\n3. What is the purpose of the absolute value function in the given text?\\n4. What is the purpose of the formula M⃗ w(⃗ xd) in the given text?\\n5. What is the purpose of the formula |yd − M⃗ w(⃗ xd)|\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='we do not care which direction the error is in, but |z| is too pointy at z = 0 making the math near\\nimpossible. Instead, we square it and sum over all data items , namely E( ⃗ w) = ∑\\nd(yd − M⃗ w(⃗ xd))2.\\nWhen the answer y is a category like “cat”, we can have the machine instead prod uce a real number\\ntelling us the “probability” that it thinks it is a “cat”. The error would then be based on how close\\nthe probability of the correct answer is to one.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text?\\n2. What is the purpose of the formula E( ⃗ w) = ∑\\nd(yd − M⃗ w(⃗ xd))2?\\n3. What is the effect of z = 0 on the math in the formula?\\n4. What is the purpose of the machine learning model in the text?\\n5. What is the main idea of the text?\\n6. What is the purpose of the\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Machine Learning: Given the training data, our goal is to ﬁnd the weights ⃗ wopt that minimizes the error\\nE( ⃗ w). This is all that machine learning is.\\n2' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 1}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary goal of machine learning?\\n2. What is the purpose of the training data in machine learning?\\n3. What is the main objective of minimizing the error E( ⃗ w)?\\n4. What is the term used to describe the weights ⃗ wopt that minimizes the error E( ⃗ w)?\\n5. What is the purpose of the weights ⃗ wopt in machine learning?\\n6. What is the relationship between the training data and\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Error Surface: We think of the error as a function of the weights ⃗ wbecause they are the parameters that\\nwe are able to tweak. If we pretend that the weights consist of one real number ⃗ w= ⟨w1⟩, then we\\ncan graph the error function on paper with w1 being the x-axis and the error E( ⃗ w) being the y-axis.\\nWe are looking for a minimum. With two real numbers ⃗ w= ⟨w1, w2⟩, we get an error surface. The' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the Error Surface concept in machine learning?\\n2. What is the purpose of the weights ⃗ w in the Error Surface concept?\\n3. What is the relationship between the weights ⃗ w1 and ⃗ w2 in the Error Surface concept?\\n4. What is the difference between the error function E( ⃗ w) and the error function E( ⃗ w1, ⃗ w2)?\\n5. What is\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='ﬁrst weight w1 can tell you your East-West location, the second w2 your North-South location, and\\nthe error E( ⃗ w) your altitude. This gives you a topological map of your erro r surface. We are looking\\nfor a location ⃗ win a valley.\\nBlind: In practice the weights ⃗ w= ⟨w1, . . . , w m⟩ consist of tens or hundreds of thousands of real numbers\\nmaking for a very high dimensional space to search. With 10,0 00 weights with 0 to 9 integer values,' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='there are 10 10,000 settings of the weights. A super computer on each atom of the u niverse working for\\nthe age of the universe couldn’t dent this list!\\nLinear Regression: If the machines are linear in the weights as in M⃗ w(⃗ xd) = w0 + w1x⟨d,1⟩ + w2x⟨d,2⟩ +\\nw3 x⟨d,2⟩2, then there are formulas that will give you the weights ⃗ wopt that minimizes the error E( ⃗ w).\\nNot so for complicated machines.\\nGradient Decent: When I asked my young son how to ﬁnd the top of the hill, he answe red “Just keep' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main purpose of the Gradient Descent algorithm in machine learning?\\n2. What is the difference between Linear Regression and Gradient Descent?\\n3. What is the formula for the weights ⃗ wopt that minimizes the error E( ⃗ w)?\\n4. What is the purpose of the Gradient Descent algorithm in machine learning?\\n5. What is the difference between Linear Regression and Gradient Descent?\\n6. What is the purpose of the Gradient Descent algorithm in\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='going up.” When ask which direction to head, he answered “in t he direction that is steepest.” When\\nask how do you know when you are at the top, he answered “When yo u can’t go up anymore.” This\\nis how we will ﬁnd the bottom of a valley. It might not ﬁnd the global minimum, but we hope that it\\nﬁnds a machine that is good enough for our purposes. From this we get self driving cars!\\nSmooth/Diﬀerentiable: This error surface is such that an inﬁnitesimally small chan ge in any one of the' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the direction to head when asked which direction to head, and how do you know when you are at the top?\\n2. What is the error surface in the metadata of the given document?\\n3. What is the purpose of the self-driving car project?\\n4. What is the difference between smooth and differentiable error surfaces?\\n5. What is the name of the document that contains the information about the self-driving car project?\\n6. What is the purpose of asking which direction to\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='weights wk causes an inﬁnitesimally small change in the output of the co rresponding neuron of the\\nneural net, in the output M⃗ w(⃗ xd) of the machine, and in the error E( ⃗ w) = ∑\\nd(yd −M⃗ w(⃗ xd)2. Dividing\\nthe change in E( ⃗ w) by the change in wk gives the derivative δE\\nδwk\\n. The vector of these derivatives\\n∆( ⃗ w) =\\n⣨\\nδE\\nδw1\\n, δE\\nδw2\\n, . . . , δE\\nδwm\\n⟩\\nis called the gradient. This is computed eﬃciently by a process called' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='back-propagation using the calculus learned in high school. The ﬁgure below pr ovides a little of the\\nmath as to why this vector gives the direction of steepest dec ent. Intuitively, the weights wk that\\ninﬂuence correct answers are increased and those that inﬂue nce wrong answers are decreased.\\nAlgorithm: Method for ﬁnding weights ⃗ wopt that minimizes the error E( ⃗ w) is as follows:\\nStart with random ⃗ w= ⟨w1, . . . , w m⟩\\nRepeat:\\n⟨loop−invariant⟩: We know where we are ⃗ w= ⟨w1, . . . , w m⟩.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main purpose of back-propagation in machine learning?\\n2. What is the term for the process of adjusting the weights of the connections between neurons in a neural network to minimize the error between predicted and actual outputs?\\n3. What is the name of the algorithm used to find the optimal weights for a neural network to minimize the error between predicted and actual outputs?\\n4. What is the term for the process of adjusting the weights of the connections between neurons in a neural network to minimize\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Calculate our height E( ⃗ w).\\n3' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 2}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the formula for calculating the height of an object in meters?\\n2. What is the unit of measurement for the height of an object in the given text?\\n3. What is the purpose of the formula E( ⃗ w) in the given text?\\n4. What is the relationship between the height of an object and its mass in the given text?\\n5. What is the unit of measurement for the height of an object in the given text?\\n6. What is the\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Calculate the direction and slope of steepest descent.\\nChange⃗ wby a small step in this direction and distance proportional t o the slope.\\nStop when every direction is up.\\nGeneralizing: This machine is optimized to do well on the training data. But how well does it generalize\\nto other inputs that it has never seen before? There is a “no fr ee lunch” theorem that says that no\\none method works in all cases. But there are a few principles. Consider the following three examples,' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of steepest descent in machine learning?\\n2. What is the slope of the steepest descent direction?\\n3. What is the purpose of changing the direction and distance in steepest descent?\\n4. What is the generalization of the machine learning model to other inputs?\\n5. What is the “no fr ee lunch” theorem?\\n6. What is the generalization of the machine learning model to other inputs?\\n7. What is the purpose of the\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='A, B, & C. Each dot give the ⟨xd, yd⟩ of one training data item. The curve gives the answer that the\\nmachine gives for each input x. Ask yourself which of these three gives the best answers for values of\\nx that it has never seen before?\\nUnderﬁtting: A is an example of Underﬁtting in which the class of machines just doesn’t have the\\ncapacity to learn the material.\\nOverﬁtting: C is an example of Overﬁtting in which the class of machines is so powerful that is can' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text?\\n2. What is the purpose of the curve in the text?\\n3. What is the difference between Underﬁtting and Overﬁtting?\\n4. What is the main idea of the text?\\n5. What is the purpose of the curve in the text?\\n6. What is the difference between Underﬁtting and Overﬁtting?\\n7. What is the main idea of the text?\\n8. What\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='memorize the answers for just about any function. The proble m is that if you cheat on the exam\\nby making a table of all the answers you were taught, then you l earn nothing and are stuck when\\na new question comes.\\nCompression: B seems like a good balance of under and over ﬁtting. On a test, if you summarize the\\nlearned material, compressing it to all ﬁt on one “cheat shee t”, then hopefully you understand it' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of the compression algorithm in the provided text?\\n2. What is the purpose of summarizing the learned material in the context of the compression algorithm?\\n3. What is the main difference between underfitting and overfitting in the context of machine learning models?\\n4. What is the role of the table of answers in the context of cheating on an exam?\\n5. What is the purpose of the compression algorithm in the context of machine learning models?\\n6. What\",\n",
              " '\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content=\\'and do well when a new question comes. Compression occurs whe n the weights ⃗ w= ⟨w1, . . . , w m⟩\\nwith which the machine learns, does not contain enough bits o f information to store the training\\ndata answers ⟨y1, . . . , y D⟩.\\nRegularization: A common way to ﬁnd this balance is to minimize not just the err or but a sum of\\nthe error and of some measure of how complex your machine is. W illiam of Ockham says “All\\nthings being equal, the simplest solution tends to be the bes t one.”\\' metadata={\\'source\\': \\'/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf\\', \\'page\\': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary purpose of compression in machine learning?\\n2. What is the difference between regularization and regularization?\\n3. What is the name of the concept that states \"All things being equal, the simplest solution tends to be the best one\"?\\n4. What is the purpose of compression in machine learning?\\n5. What is the term used to describe the process of minimizing the sum of the error and the complexity of the machine?\\n6. What is the name of the algorithm that uses',\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Theory: Learnable Probably Approximately Correct (PAC): If on the randomly chosen\\ntraining data, a machine is found that gives good answers, ev en though compression is required,\\nthen we can prove that with high probability this same machin e will also work well on never seen\\nbefore instances. The proof does not measure the quality of t he machine but of the training data.\\nIf the data is chosen randomly then with high probability it i s representative of the entire universe\\nof possible data.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the theory of PAC?\\n2. What is the significance of the training data in the context of PAC?\\n3. What is the relationship between the PAC theorem and the concept of compression?\\n4. What is the purpose of the proof in the context of PAC?\\n5. What is the significance of the quality of the training data in the context of PAC?\\n6. What is the relationship between the PAC theorem and the concept of universality?\\n7. What is\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='of possible data.\\nNeural Networks: Let’s now understand neural networks in more detail. It is ma de of layers of artiﬁcial\\nneurons. The input layer has an input wire for each pixel of th e input image receiving a value between\\n0-1 indicating the pixel’s brightness. The output layer has a wire for each category indicating the\\n“probability” that the input image is in fact a cat or dog. In b etween, the layers are said to be' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of the input layer in a neural network?\\n2. What is the purpose of the output layer in a neural network?\\n3. What is the role of the hidden layers in a neural network?\\n4. What is the difference between a neural network and a traditional machine learning model?\\n5. What is the primary function of the output layer in a neural network?\\n6. What is the purpose of the hidden layers in a neural network?\\n7. What is the role\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='hidden. These have no human designated meaning. Meaning is “learne d” by choosing weights ⃗ w=\\n⟨w1, . . . , w m⟩.\\n4' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 3}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the weights in the formula?\\n2. What is the value of w1 in the formula?\\n3. What is the value of w2 in the formula?\\n4. What is the value of w3 in the formula?\\n5. What is the value of w4 in the formula?\\n6. What is the value of w5 in the formula?\\n7. What is the value of w6 in the formula?\\n8. What is the value of w7\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='When a neuron in the brain ﬁres, it sends a signal to its neighbors across it s synapses. These synapses\\nhave diﬀerent weights in their inﬂuence. When a neuron’s inc oming signal reaches a threshold it ﬁres.\\nSimilarly, an artiﬁcial neuron takes a real valued signal xi along each of its incoming edges, multiplies\\nthis by the edge’s weight wi, and ﬁres if the weighted sum z = ∑\\ni=0..n xiwi reaches its threshold. In' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of the synapses in the brain?\\n2. What is the process called when a neuron fires?\\n3. What is the threshold value that an artificial neuron must reach to fire?\\n4. What is the purpose of the weights in the artificial neuron?\\n5. What is the purpose of the sum of the weighted inputs in the artificial neuron?\\n6. What is the purpose of the threshold value in the artificial neuron?\\n7. What is the purpose of the artificial neuron\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='this way, a neuron is able to compute a And, Or, or Not gate and hence is powerful enough to be able\\nto compute anything a digital computer can compute. So we can later do gradient decent, we change\\nthe threshold activation y = σ(z) so that it transitions gracefully. Instead of YES/NO we all ow maybe\\nso, i.e. if the weighted sum is close to its threshold, then it outputs a half instead of 0-1.\\nVectors: Let’s try to understand how to best think about all of these nu mbers. A data input ⃗ x=' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary function of a neuron in a digital computer?\\n2. What is the difference between a weighted sum and a threshold activation in neural networks?\\n3. What is the purpose of gradient descent in neural networks?\\n4. What is the role of vectors in neural networks?\\n5. What is the difference between a data input and a vector in neural networks?\\n6. What is the purpose of the sigmoid function in neural networks?\\n7. What is the difference between a weighted sum and\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='⟨x1, . . . , x m⟩, eg a image of a cat, is just a large tuple of real values. As suc h it can be thought as\\na point in some high dimensional vector space. Whether the im age is of a cat or a dog partitions\\nthis vector space into regions. Classifying your image amou nts to knowing which region the\\ncorresponding point is in. A linear separator separates two regions with a plane. It is unlikely\\nthat this will work to separate cats from dogs. Instead, each layer of the neural network transforms' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text about the neural network and image classification?\\n2. What is the purpose of the metadata in the given document?\\n3. What is the main concept being discussed in the text about the neural network and image classification?\\n4. What is the role of the metadata in the given document?\\n5. What is the main idea of the text about the neural network and image classification?\\n6. What is the purpose of the metadata in the given document?\\n7.\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='the input ⃗ xuntil it can categorize it.\\nCorrelation of Vectors: Machine Learning is all about ﬁnding complex correlations. Suppose I am\\nstarting a dating service. For each client I will collect pro perties. For each pair of clients, we\\nmeasure how compatible they are. The ﬁrst two clients in the ﬁ gure below each like movies a\\nlot. This adds 15 × 20 = 300 to their compatibility. They are both neutral on natu re, adding' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the primary goal of correlation of vectors in machine learning?\\n2. What is the purpose of the metadata in the provided document?\\n3. What is the relationship between the compatibility of two clients in a dating service and their movie preferences?\\n4. What is the effect of adding 15 × 20 = 300 to the compatibility of two clients in a dating service?\\n5. What is the purpose of the metadata in the provided document?\\n6. What is the relationship between the compatibility\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='only 3 × 2 = 6. They diﬀer on being extroverted making them ( −20) × 30 = −600 incompatible.\\nSumming over all properties gives a total compatibility of - 874, i.e. incompatible. The ﬁrst and\\nthird client with 910 are much more compatible.\\n5' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 4}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the compatibility of the first and third client with 910?\\n2. What is the compatibility of the second and fourth client with 910?\\n3. What is the compatibility of the fifth and sixth client with 910?\\n4. What is the compatibility of the seventh and eighth client with 910?\\n5. What is the compatibility of the ninth and tenth client with 910?\\n6. What is the compatibility of the eleventh and twelfth client with 910?\\n7.\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Denote the vector/tuple of values for the ﬁrst client with ⃗ w= ⟨w1, . . . , w m⟩ and with the second\\nwith ⃗ x= ⟨x1, . . . , x m⟩, their compatibility( ⃗ w, ⃗ x) is computed as ∑\\ni wixi. This is called the dot\\nproduct ⃗ w· ⃗ xbetween these vectors. If these vectors are thought of arrow s in high dimensional\\nspace then the angle between them is given by cos(Θ) = ⃗ w·⃗ x\\n| ⃗ w|·|⃗ x| . If ⃗ w· ⃗ xis positive, the angle Θ' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the dot product of two vectors ⃗ w and ⃗ x?\\n2. What is the angle between two vectors ⃗ w and ⃗ x?\\n3. What is the dot product of a vector ⃗ w and a scalar ⃗ k?\\n4. What is the dot product of two vectors ⃗ w and ⃗ x, where ⃗ w and ⃗ x are in the same direction?\\n5. What\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='is less than ninety degrees and if it is negative, then it is mo re. If you shine a light perpendicular\\ndown onto ⃗ w, the length of ⃗ x’s projection will be |⃗ x| · cos(Θ) = ⃗ w·⃗ x\\n| ⃗ w| . For some given distance d,\\nthe set of all vectors ⃗ xwith this projection length equaling d are those within the hyper-plane\\nperpendicular to ⃗ wa distance d from the origin. When ⃗ w·⃗ x\\n| ⃗ w| is less than this d, then ⃗ xis on the\\nnear side of this plane and when more than it is on the far side.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the relationship between the angle of incidence and the angle of reflection?\\n2. What is the formula for the projection of a vector ⃗ x onto a vector ⃗ w?\\n3. What is the condition for a vector ⃗ x to be on the near side of a hyper-plane perpendicular to vector ⃗ w?\\n4. What is the formula for the projection of a vector ⃗ x onto a vector ⃗ w?\\n5. What is\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Linear Layer = Matrix Multiplication: The simplest layer of a neural network is linear. A novice\\nreading a machine learning paper might not get that many of th e symbols are not real numbers\\nbut are matrices. Hence the product of two such symbols is mat rix multiplication.\\nConsider feeding the dth training data input ⃗ xd =\\n⟨\\nx⟨d,1⟩, . . . , x ⟨d,m⟩\\n⟩\\ninto the neural network. Its\\nith value x⟨d,i⟩ is fed into the network’s ith input wire. The set of all of these values x⟨d,i⟩ can be' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the linear layer in a neural network?\\n2. What is the difference between matrix multiplication and linear layer in a neural network?\\n3. What is the role of the input data in the neural network?\\n4. What is the purpose of the output layer in a neural network?\\n5. What is the difference between the weights and biases in a neural network?\\n6. What is the purpose of the activation function in a neural network?\\n7. What is the role of\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='organized into a matrix X =\\n[\\nx⟨d,i⟩\\n]\\n⟨d,i⟩ whose dth row corresponds this dth training data input\\n⃗ xd.\\nLet w⟨i,j⟩ denote the weight of the edge from the ith input wire to the jth artiﬁcial neuron in the\\nﬁrst layer of the network. These values can be also be organiz ed into a matrix W =\\n[\\nw⟨i,j⟩\\n]\\n⟨i,j⟩.\\nThe total incoming signal into the jth hidden neuron on the dth input ⃗ xd is denoted z⟨d,j⟩. Again\\nthese values form a matrix Z =\\n[\\nz⟨d,j⟩\\n]\\n⟨d,j⟩.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the matrix X in the given equation?\\n2. What is the purpose of the matrix W in the given equation?\\n3. What is the total incoming signal into the jth hidden neuron on the dth input ⃗ xd?\\n4. What is the total incoming signal into the jth hidden neuron on the dth input ⃗ xd?\\n5. What is the total incoming signal into the jth hidden neuron on the dth input ⃗\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='[\\nz⟨d,j⟩\\n]\\n⟨d,j⟩.\\nThis jth hidden neuron has many incoming edges, the ith of which is labeled with weight w⟨i,j⟩ and\\nreceives the input value x⟨d,i⟩. These are multiplied and these products for the diﬀerent in coming\\nedges are added together, i.e. z⟨d,j⟩ = x⟨d,1⟩ ×w⟨1,j⟩ +. . . +x⟨d,I⟩ ×w⟨I,j ⟩ = ∑\\ni x⟨d,i⟩ ×w⟨i,j⟩. Note\\nthat this is the exact calculation computed in the matrix mul tiplication Z = X × W as the ⟨d, j⟩' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the matrix multiplication in the given equation?\\n2. What is the value of the weight vector w⟨i,j⟩ for the ith hidden neuron?\\n3. What is the value of the input value x⟨d,i⟩ for the ith hidden neuron?\\n4. What is the value of the sum of products of the ith hidden neuron and the ith input value?\\n5. What is the value of the weight vector w⟨i,j⟩ for the j\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='entry of matrix Z is given by the dot product of the dth row of matrix X and the jth column of\\nmatrix W , summing over index i.\\nNon-Linear Layer: Given signal z⟨d,j⟩, the jth hidden neuron ideally either ﬁres or it doesn’t. The\\npicture is either a cat or not. One might model this by having t he hidden neuron ﬁre if this\\n6' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 5}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the dot product in the non-linear layer of a neural network?\\n2. What is the purpose of the hidden neuron firing in the non-linear layer?\\n3. What is the purpose of the metadata in the question?\\n4. What is the purpose of the jth column of matrix W in the non-linear layer?\\n5. What is the purpose of the jth row of matrix X in the non-linear layer?\\n6. What is the purpose of the summing\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='signal z⟨d,j⟩ passes a threshold. Typically, a constant w⟨0,j⟩ is added into the sum so that the\\nthreshold is shifted to zero. To be more graceful, a typical a ctivation function used is the sigmoid\\nfunction y⟨d,j⟩ = σ(z⟨d,j⟩) that has the hidden neuron output close to one when input sum z⟨d,j⟩ is\\nvery positive, output close to zero when it is very negative, and in between it changes gracefully.\\nThe problem with the sigmoid activation function is that its derivative and hence the gradient' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the typical value of the constant w⟨0,j⟩ added to the sum of the input z⟨d,j⟩ to shift the threshold to zero?\\n2. What is the typical activation function used in the neural network, and what is its mathematical representation?\\n3. What is the typical output of the sigmoid function when the input sum z⟨d,j⟩ is very positive?\\n4. What is the typical output of the sigmoid function when the input sum z⟨\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='of steepest decent is close zero for large activation values z making learning slow. To solve this\\nproblem, the rectilinear activation function does not chan ge the signal, i.e. y = z when it is\\npositive and zeros it, i.e. y = 0, when negative. Note for positive z, the slope here is always one\\nmaking learning faster. Recent work has shown that this acti vation function works surprisingly\\nwell for many applications.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main idea of the text?\\n2. What is the purpose of the rectilinear activation function?\\n3. What is the effect of the activation function on the learning process?\\n4. What is the significance of the activation function in machine learning?\\n5. What is the relationship between the activation function and the learning process?\\n6. What is the effect of the activation function on the signal when it is positive?\\n7. What is the effect of the activation function on the signal when\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Convolution and Recurrent Layer: Suppose the input is an image and the neural network is\\ntrained to ﬁnd a cat. This problem is invariant over the locat ion of the cat, namely the net-\\nwork should answer yes no matter where in the image the cat is l ocated. This invariant can be\\nbuilt into the design of the neural network by having a set of w eights be learned to ﬁnd a feature\\nin some small part of the image and to use those same weights tr anslated all over the image.' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main goal of the neural network in this problem?\\n2. What type of feature is being learned by the neural network?\\n3. What is the purpose of the weights being learned by the neural network?\\n4. What is the location of the cat in the image that the neural network is supposed to find?\\n5. What is the purpose of translating the weights across the image?\\n6. What is the type of feature that the neural network is using to find the cat?\\n7\",\n",
              " \"\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content='Similarly, if the input in a stream of speech, then the same se t of weights can detect the word cat\\nat the beginning and at the end of the stream. These changes de crease the number of weights\\nthat the neural network has, making learning easier, decrea sing computation time, and decreasing\\noverﬁtting.\\nThe Singularity: If technology grows just slightly faster than exponentiall y, then at some point in time,\\nthe expected about of technology will be inﬁnite. What will l ife look like after that?' metadata={'source': '/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf', 'page': 6}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the purpose of the weights in the neural network?\\n2. What is the expected outcome of technology growing faster than exponentialy?\\n3. What is the expected outcome of the expected outcome of technology growing faster than exponentialy?\\n4. What is the expected outcome of the expected outcome of technology growing faster than exponentialy?\\n5. What is the expected outcome of the expected outcome of technology growing faster than exponentialy?\\n6. What is the expected outcome of the expected outcome of technology growing\",\n",
              " '\\nYou are an expert at creating questions based on study materials and documentation.\\nYour goal is to prepare a student for their exam.\\nYou do this by  asking questions about the text below:\\n\\npage_content=\\'7\\' metadata={\\'source\\': \\'/content/drive/MyDrive/NLP_PROJECT/machine_learning.pdf\\', \\'page\\': 6}\\n\\nCreate 10 questions that will prepare students for their exam\\nand make sure you dont generate similar questions\\nand take only scientific important information.\\n\\nQuestions:\\n1. What is the main purpose of the chapter on \"Machine Learning\" in the provided document?\\n2. What is the difference between a supervised and unsupervised learning algorithm?\\n3. What is the role of the dataset in machine learning?\\n4. What is the purpose of the feature engineering process in machine learning?\\n5. What is the difference between a linear and non-linear regression model?\\n6. What is the role of the model evaluation metrics in machine learning?\\n7. What is the difference']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = questions"
      ],
      "metadata": {
        "id": "CAICqmhNkIjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Function to extract context and questions\n",
        "def extract_context_and_questions(item):\n",
        "    context_part = item.split(\"below:\")[1].split(\"Questions:\")[0].strip()\n",
        "    questions_part = item.split(\"Questions:\")[1].strip()\n",
        "    return context_part, questions_part\n",
        "\n",
        "# Process the items and store the data in a DataFrame\n",
        "data = []\n",
        "for item in items:\n",
        "    context, questions = extract_context_and_questions(item)\n",
        "    data.append({\"Context\": context, \"Questions\": questions})\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biNnVRo_CRBf",
        "outputId": "c91da8b8-5240-487b-afcd-56000f9269db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Context  \\\n",
            "0   page_content='Chapter on Machine Learning\\nBy ...   \n",
            "1   page_content='years of learning. The machine i...   \n",
            "2   page_content='bottom of a valley. “Gradient De...   \n",
            "3   page_content='Coding: When writing computer co...   \n",
            "4   page_content='algorithm, ﬁnding patterns in lo...   \n",
            "5   page_content='cial, and legal experts. Hopeful...   \n",
            "6   page_content='nature of the machine or the nat...   \n",
            "7   page_content='Supervised Training Data: The in...   \n",
            "8   page_content='categorizing. Another way of vis...   \n",
            "9   page_content='do it.\\nMachine: Our goal is to ...   \n",
            "10  page_content='whether there are clouds, x⟨d,2⟩...   \n",
            "11  page_content='adding additional terms like + w...   \n",
            "12  page_content='be much harder.\\nNeural Networks...   \n",
            "13  page_content='The easiest thing to do would be...   \n",
            "14  page_content='we do not care which direction t...   \n",
            "15  page_content='Machine Learning: Given the trai...   \n",
            "16  page_content='Error Surface: We think of the e...   \n",
            "17  page_content='ﬁrst weight w1 can tell you your...   \n",
            "18  page_content='there are 10 10,000 settings of ...   \n",
            "19  page_content='going up.” When ask which direct...   \n",
            "20  page_content='weights wk causes an inﬁnitesima...   \n",
            "21  page_content='back-propagation using the calcu...   \n",
            "22  page_content='Calculate our height E( ⃗ w).\\n3...   \n",
            "23  page_content='Calculate the direction and slop...   \n",
            "24  page_content='A, B, & C. Each dot give the ⟨xd...   \n",
            "25  page_content='memorize the answers for just ab...   \n",
            "26  page_content='and do well when a new question ...   \n",
            "27  page_content='Theory: Learnable Probably Appro...   \n",
            "28  page_content='of possible data.\\nNeural Networ...   \n",
            "29  page_content='hidden. These have no human desi...   \n",
            "30  page_content='When a neuron in the brain ﬁres,...   \n",
            "31  page_content='this way, a neuron is able to co...   \n",
            "32  page_content='⟨x1, . . . , x m⟩, eg a image of...   \n",
            "33  page_content='the input ⃗ xuntil it can catego...   \n",
            "34  page_content='only 3 × 2 = 6. They diﬀer on be...   \n",
            "35  page_content='Denote the vector/tuple of value...   \n",
            "36  page_content='is less than ninety degrees and ...   \n",
            "37  page_content='Linear Layer = Matrix Multiplica...   \n",
            "38  page_content='organized into a matrix X =\\n[\\n...   \n",
            "39  page_content='[\\nz⟨d,j⟩\\n]\\n⟨d,j⟩.\\nThis jth h...   \n",
            "40  page_content='entry of matrix Z is given by th...   \n",
            "41  page_content='signal z⟨d,j⟩ passes a threshold...   \n",
            "42  page_content='of steepest decent is close zero...   \n",
            "43  page_content='Convolution and Recurrent Layer:...   \n",
            "44  page_content='Similarly, if the input in a str...   \n",
            "45  page_content='7' metadata={'source': '/content...   \n",
            "\n",
            "                                            Questions  \n",
            "0   1. What is the main idea of the chapter on Mac...  \n",
            "1   1. What is the primary function of a neural ne...  \n",
            "2   1. What is the main idea of the text?\\n2. What...  \n",
            "3   1. What is the primary purpose of machine lear...  \n",
            "4   1. What is the primary goal of machine learnin...  \n",
            "5   1. What is the primary function of machine lea...  \n",
            "6   1. What is the main idea of the text?\\n2. What...  \n",
            "7   1. What is the primary purpose of the supervis...  \n",
            "8   1. What is the main idea of the text?\\n2. What...  \n",
            "9   1. What is the primary goal of the machine lea...  \n",
            "10  1. What is the main purpose of the machine lea...  \n",
            "11                                                     \n",
            "12  1. What is the primary function of the weights...  \n",
            "13  1. What is the purpose of the machine learning...  \n",
            "14  1. What is the main idea of the text?\\n2. What...  \n",
            "15  1. What is the primary goal of machine learnin...  \n",
            "16  1. What is the main idea of the Error Surface ...  \n",
            "17                                                     \n",
            "18  1. What is the main purpose of the Gradient De...  \n",
            "19  1. What is the direction to head when asked wh...  \n",
            "20                                                     \n",
            "21  1. What is the main purpose of back-propagatio...  \n",
            "22  1. What is the formula for calculating the hei...  \n",
            "23  1. What is the purpose of steepest descent in ...  \n",
            "24  1. What is the main idea of the text?\\n2. What...  \n",
            "25  1. What is the primary function of the compres...  \n",
            "26  1. What is the primary purpose of compression ...  \n",
            "27  1. What is the main idea of the theory of PAC?...  \n",
            "28  1. What is the primary function of the input l...  \n",
            "29  1. What is the purpose of the weights in the f...  \n",
            "30  1. What is the primary function of the synapse...  \n",
            "31  1. What is the primary function of a neuron in...  \n",
            "32  1. What is the main idea of the text about the...  \n",
            "33  1. What is the primary goal of correlation of ...  \n",
            "34  1. What is the compatibility of the first and ...  \n",
            "35  1. What is the dot product of two vectors ⃗ w ...  \n",
            "36  1. What is the relationship between the angle ...  \n",
            "37  1. What is the purpose of the linear layer in ...  \n",
            "38  1. What is the purpose of the matrix X in the ...  \n",
            "39  1. What is the purpose of the matrix multiplic...  \n",
            "40  1. What is the purpose of the dot product in t...  \n",
            "41  1. What is the typical value of the constant w...  \n",
            "42  1. What is the main idea of the text?\\n2. What...  \n",
            "43  1. What is the main goal of the neural network...  \n",
            "44  1. What is the purpose of the weights in the n...  \n",
            "45  1. What is the main purpose of the chapter on ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "import pandas as pd\n",
        "\n",
        "# Define the model using HuggingFaceHub\n",
        "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",model_kwargs=dict(temperature=0.1),)"
      ],
      "metadata": {
        "id": "wDSBrW7aaMox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the answer template\n",
        "answer_template = \"\"\"\n",
        "Answer the following question based on the text:\n",
        "\n",
        "Text: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KoMRPSmCaMsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(context, question):\n",
        "    # Fill in the template\n",
        "    input_text = answer_template.format(context=context, question=question)\n",
        "    # Generate the answer using the LLM\n",
        "    answer = llm(input_text)\n",
        "    return answer.strip()"
      ],
      "metadata": {
        "id": "BfmoaVOuE3gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Answers\"] = df.apply(\n",
        "    lambda row: \"\\n\".join(\n",
        "        [generate_answer(row[\"Context\"], q.strip()) for q in row[\"Questions\"].split(\"\\n\")]\n",
        "    ),\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf9WU_VwFCzX",
        "outputId": "74319bed-15aa-4ddc-c2e6-15841c40330e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Context  \\\n",
            "0   page_content='Chapter on Machine Learning\\nBy ...   \n",
            "1   page_content='years of learning. The machine i...   \n",
            "2   page_content='bottom of a valley. “Gradient De...   \n",
            "3   page_content='Coding: When writing computer co...   \n",
            "4   page_content='algorithm, ﬁnding patterns in lo...   \n",
            "5   page_content='cial, and legal experts. Hopeful...   \n",
            "6   page_content='nature of the machine or the nat...   \n",
            "7   page_content='Supervised Training Data: The in...   \n",
            "8   page_content='categorizing. Another way of vis...   \n",
            "9   page_content='do it.\\nMachine: Our goal is to ...   \n",
            "10  page_content='whether there are clouds, x⟨d,2⟩...   \n",
            "11  page_content='adding additional terms like + w...   \n",
            "12  page_content='be much harder.\\nNeural Networks...   \n",
            "13  page_content='The easiest thing to do would be...   \n",
            "14  page_content='we do not care which direction t...   \n",
            "15  page_content='Machine Learning: Given the trai...   \n",
            "16  page_content='Error Surface: We think of the e...   \n",
            "17  page_content='ﬁrst weight w1 can tell you your...   \n",
            "18  page_content='there are 10 10,000 settings of ...   \n",
            "19  page_content='going up.” When ask which direct...   \n",
            "20  page_content='weights wk causes an inﬁnitesima...   \n",
            "21  page_content='back-propagation using the calcu...   \n",
            "22  page_content='Calculate our height E( ⃗ w).\\n3...   \n",
            "23  page_content='Calculate the direction and slop...   \n",
            "24  page_content='A, B, & C. Each dot give the ⟨xd...   \n",
            "25  page_content='memorize the answers for just ab...   \n",
            "26  page_content='and do well when a new question ...   \n",
            "27  page_content='Theory: Learnable Probably Appro...   \n",
            "28  page_content='of possible data.\\nNeural Networ...   \n",
            "29  page_content='hidden. These have no human desi...   \n",
            "30  page_content='When a neuron in the brain ﬁres,...   \n",
            "31  page_content='this way, a neuron is able to co...   \n",
            "32  page_content='⟨x1, . . . , x m⟩, eg a image of...   \n",
            "33  page_content='the input ⃗ xuntil it can catego...   \n",
            "34  page_content='only 3 × 2 = 6. They diﬀer on be...   \n",
            "35  page_content='Denote the vector/tuple of value...   \n",
            "36  page_content='is less than ninety degrees and ...   \n",
            "37  page_content='Linear Layer = Matrix Multiplica...   \n",
            "38  page_content='organized into a matrix X =\\n[\\n...   \n",
            "39  page_content='[\\nz⟨d,j⟩\\n]\\n⟨d,j⟩.\\nThis jth h...   \n",
            "40  page_content='entry of matrix Z is given by th...   \n",
            "41  page_content='signal z⟨d,j⟩ passes a threshold...   \n",
            "42  page_content='of steepest decent is close zero...   \n",
            "43  page_content='Convolution and Recurrent Layer:...   \n",
            "44  page_content='Similarly, if the input in a str...   \n",
            "45  page_content='7' metadata={'source': '/content...   \n",
            "\n",
            "                                            Questions  \\\n",
            "0   1. What is the main idea of the chapter on Mac...   \n",
            "1   1. What is the primary function of a neural ne...   \n",
            "2   1. What is the main idea of the text?\\n2. What...   \n",
            "3   1. What is the primary purpose of machine lear...   \n",
            "4   1. What is the primary goal of machine learnin...   \n",
            "5   1. What is the primary function of machine lea...   \n",
            "6   1. What is the main idea of the text?\\n2. What...   \n",
            "7   1. What is the primary purpose of the supervis...   \n",
            "8   1. What is the main idea of the text?\\n2. What...   \n",
            "9   1. What is the primary goal of the machine lea...   \n",
            "10  1. What is the main purpose of the machine lea...   \n",
            "11                                                      \n",
            "12  1. What is the primary function of the weights...   \n",
            "13  1. What is the purpose of the machine learning...   \n",
            "14  1. What is the main idea of the text?\\n2. What...   \n",
            "15  1. What is the primary goal of machine learnin...   \n",
            "16  1. What is the main idea of the Error Surface ...   \n",
            "17                                                      \n",
            "18  1. What is the main purpose of the Gradient De...   \n",
            "19  1. What is the direction to head when asked wh...   \n",
            "20                                                      \n",
            "21  1. What is the main purpose of back-propagatio...   \n",
            "22  1. What is the formula for calculating the hei...   \n",
            "23  1. What is the purpose of steepest descent in ...   \n",
            "24  1. What is the main idea of the text?\\n2. What...   \n",
            "25  1. What is the primary function of the compres...   \n",
            "26  1. What is the primary purpose of compression ...   \n",
            "27  1. What is the main idea of the theory of PAC?...   \n",
            "28  1. What is the primary function of the input l...   \n",
            "29  1. What is the purpose of the weights in the f...   \n",
            "30  1. What is the primary function of the synapse...   \n",
            "31  1. What is the primary function of a neuron in...   \n",
            "32  1. What is the main idea of the text about the...   \n",
            "33  1. What is the primary goal of correlation of ...   \n",
            "34  1. What is the compatibility of the first and ...   \n",
            "35  1. What is the dot product of two vectors ⃗ w ...   \n",
            "36  1. What is the relationship between the angle ...   \n",
            "37  1. What is the purpose of the linear layer in ...   \n",
            "38  1. What is the purpose of the matrix X in the ...   \n",
            "39  1. What is the purpose of the matrix multiplic...   \n",
            "40  1. What is the purpose of the dot product in t...   \n",
            "41  1. What is the typical value of the constant w...   \n",
            "42  1. What is the main idea of the text?\\n2. What...   \n",
            "43  1. What is the main goal of the neural network...   \n",
            "44  1. What is the purpose of the weights in the n...   \n",
            "45  1. What is the main purpose of the chapter on ...   \n",
            "\n",
            "                                              Answers  \n",
            "0   Answer the following question based on the tex...  \n",
            "1   Answer the following question based on the tex...  \n",
            "2   Answer the following question based on the tex...  \n",
            "3   Answer the following question based on the tex...  \n",
            "4   Answer the following question based on the tex...  \n",
            "5   Answer the following question based on the tex...  \n",
            "6   Answer the following question based on the tex...  \n",
            "7   Answer the following question based on the tex...  \n",
            "8   Answer the following question based on the tex...  \n",
            "9   Answer the following question based on the tex...  \n",
            "10  Answer the following question based on the tex...  \n",
            "11  Answer the following question based on the tex...  \n",
            "12  Answer the following question based on the tex...  \n",
            "13  Answer the following question based on the tex...  \n",
            "14  Answer the following question based on the tex...  \n",
            "15  Answer the following question based on the tex...  \n",
            "16  Answer the following question based on the tex...  \n",
            "17  Answer the following question based on the tex...  \n",
            "18  Answer the following question based on the tex...  \n",
            "19  Answer the following question based on the tex...  \n",
            "20  Answer the following question based on the tex...  \n",
            "21  Answer the following question based on the tex...  \n",
            "22  Answer the following question based on the tex...  \n",
            "23  Answer the following question based on the tex...  \n",
            "24  Answer the following question based on the tex...  \n",
            "25  Answer the following question based on the tex...  \n",
            "26  Answer the following question based on the tex...  \n",
            "27  Answer the following question based on the tex...  \n",
            "28  Answer the following question based on the tex...  \n",
            "29  Answer the following question based on the tex...  \n",
            "30  Answer the following question based on the tex...  \n",
            "31  Answer the following question based on the tex...  \n",
            "32  Answer the following question based on the tex...  \n",
            "33  Answer the following question based on the tex...  \n",
            "34  Answer the following question based on the tex...  \n",
            "35  Answer the following question based on the tex...  \n",
            "36  Answer the following question based on the tex...  \n",
            "37  Answer the following question based on the tex...  \n",
            "38  Answer the following question based on the tex...  \n",
            "39  Answer the following question based on the tex...  \n",
            "40  Answer the following question based on the tex...  \n",
            "41  Answer the following question based on the tex...  \n",
            "42  Answer the following question based on the tex...  \n",
            "43  Answer the following question based on the tex...  \n",
            "44  Answer the following question based on the tex...  \n",
            "45  Answer the following question based on the tex...  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}